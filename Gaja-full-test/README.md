# GAJA Full Test - End-to-End Testing Framework

Kompletny system testÃ³w end-to-end dla asystenta GAJA, ktÃ³ry wykonuje realne testy przez API, generuje audio przez TTS, ocenia odpowiedzi przez lokalnÄ… instancjÄ™ LLM i tworzy szczegÃ³Å‚owe raporty HTML.

## ğŸ¯ Funkcje

- **Realne testy API** - zero mockÃ³w, tylko prawdziwe wywoÅ‚ania REST/WebSocket
- **Audio processing** - generowanie TTS przez OpenAI, planowana obsÅ‚uga Whisper
- **Inteligentna ocena** - lokalna instancja LM Studio ocenia jakoÅ›Ä‡ odpowiedzi
- **Akcje systemowe** - restart serwera, zarzÄ…dzanie cache, backup danych
- **Interaktywny raport HTML** - automatycznie otwierany w przeglÄ…darce

## ğŸ“‹ Wymagania

### System
- Python 3.11+
- FFmpeg (wymagane przez pydub)
- LM Studio z modelem gpt-oss-20b (opcjonalnie dla oceny semantycznej)

### Serwisy
- GAJA Server dziaÅ‚ajÄ…cy na `http://localhost:8001`
- LM Studio na `http://localhost:1234` (opcjonalnie)

## ğŸš€ Instalacja

1. **Sklonuj/przejdÅº do folderu:**
   ```bash
   cd Gaja-full-test
   ```

2. **UtwÃ³rz Å›rodowisko wirtualne:**
   ```bash
   python -m venv .venv
   
   # Windows
   .venv\Scripts\activate
   
   # Linux/Mac
   source .venv/bin/activate
   ```

3. **Zainstaluj zaleÅ¼noÅ›ci:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Skonfiguruj zmienne Å›rodowiskowe:**
   ```bash
   cp .env.example .env
   ```
   
   WypeÅ‚nij `.env`:
   ```env
   GAJA_API_KEY=your_gaja_api_key_if_needed
   OPENAI_API_KEY=your_openai_api_key_for_tts
   ```

5. **SprawdÅº FFmpeg:**
   ```bash
   ffmpeg -version
   ```

## âš™ï¸ Konfiguracja

Edytuj `config.yaml` aby dostosowaÄ‡ ustawienia:

```yaml
gaja:
  base_url: "http://localhost:8001"    # URL serwera GAJA
  api_key: "${GAJA_API_KEY}"           # Klucz API (jeÅ›li wymagany)

voice:
  tts_provider: "openai"
  tts_model: "tts-1"                   # Model OpenAI TTS
  tts_voice: "alloy"                   # GÅ‚os (alloy, echo, fable, onyx, nova, shimmer)
  sample_rate: 16000
  output_format: "wav"

grader:
  lmstudio_base_url: "http://localhost:1234/v1/chat/completions"
  model: "gpt-oss-20b"                 # Model w LM Studio
  max_tokens: 512
  temperature: 0.1

report:
  output_path: "results/report.html"
  fail_threshold: 8.0                  # PrÃ³g oceny (0-10)

runtime:
  seed: 42
  default_timeout_s: 45
  between_steps_sleep_ms: 300
  allow_parallel: false
```

## ğŸ® Uruchomienie

### Pojedynczy scenariusz
```bash
python src/runner.py --scenario scenarios/conversation_basic.yaml
```

### Wszystkie scenariusze
```bash
python src/runner.py --all
```

### Niestandardowa konfiguracja
```bash
python src/runner.py --all --config custom_config.yaml
```

## ğŸ“ Scenariusze testowe

Scenariusze sÄ… zdefiniowane w plikach YAML w folderze `scenarios/`:

### DostÄ™pne scenariusze:
- `conversation_basic.yaml` - Podstawowa konwersacja
- `habits_learning.yaml` - Dodawanie i przypominanie nawykÃ³w
- `tts_roundtrip.yaml` - Test peÅ‚nej pÄ™tli audio (TTS â†’ GAJA â†’ odpowiedÅº)
- `whisper_input.yaml` - Przetwarzanie wejÅ›cia audio
- `calendar_integration.yaml` - Integracja z kalendarzem
- `notes_plugin.yaml` - FunkcjonalnoÅ›Ä‡ notatek
- `web_search.yaml` - Wyszukiwanie w internecie
- `iot_smart_home.yaml` - Kontrola urzÄ…dzeÅ„ IoT
- `longform_generation.yaml` - Generowanie dÅ‚ugich treÅ›ci

### Struktura scenariusza:

```yaml
meta:
  name: "Test Name"
  tags: ["tag1", "tag2"]

steps:
  - type: "text"                    # text|audio|action
    message: "CzeÅ›Ä‡! Jak siÄ™ masz?"
    expect:
      action: "greeting_response"
      assertions:
        - kind: "contains"          # contains|semantic_ok|effect_ok|jsonpath_eq
          target: "assistant_text"  # assistant_text|plugin_result|side_effect
          value: "czeÅ›Ä‡"
        - kind: "semantic_ok"

  - type: "audio"
    tts_text: "Wygeneruj audio z tego tekstu"
    expect:
      action: "transcribe_and_answer"
      assertions:
        - kind: "semantic_ok"

  - type: "action"
    action: "restart_gaja"          # restart_gaja|clear_cache|backup_data
    expect:
      action: "service_restarted"
      assertions:
        - kind: "effect_ok"
```

## ğŸ“Š Interpretacja wynikÃ³w

### Raport HTML
Po uruchomieniu testÃ³w automatycznie otwiera siÄ™ raport HTML zawierajÄ…cy:

- **Statystyki ogÃ³lne** - liczba scenariuszy, krokÃ³w, wskaÅºnik sukcesu
- **Wykresy wizualne** - sÅ‚upkowe i koÅ‚owe przedstawienie wynikÃ³w
- **SzczegÃ³Å‚owe wyniki** - tabela z wynikami kaÅ¼dego scenariusza
- **Nieudane testy** - lista bÅ‚Ä™dÃ³w z detalami
- **Konfiguracja** - ustawienia uÅ¼yte podczas testÃ³w

### Progi oceny
- **semantic_ok**: ocena LM Studio â‰¥ 8.0/10 (konfigurowalny prÃ³g)
- **effect_ok**: sprawdzenie czy akcja systemowa siÄ™ powiodÅ‚a
- **contains**: czy tekst zawiera oczekiwanÄ… frazÄ™

### Pliki wynikowe
```
results/
â”œâ”€â”€ report.html              # GÅ‚Ã³wny raport
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ test_run_*.jsonl     # Logi wykonania (JSON Lines)
â”‚   â””â”€â”€ grades_*.json        # Oceny z LM Studio
â””â”€â”€ artifacts/
    â”œâ”€â”€ tts_input_*.wav      # Pliki audio wejÅ›ciowe (TTS)
    â””â”€â”€ tts_output_*.opus    # Pliki audio wyjÅ›ciowe (GAJA)
```

## ğŸ”§ RozwiÄ…zywanie problemÃ³w

### FFmpeg nie znaleziony
```bash
# Windows (przez chocolatey)
choco install ffmpeg

# Windows (rÄ™cznie)
# Pobierz z https://ffmpeg.org/download.html i dodaj do PATH

# Ubuntu/Debian
sudo apt update && sudo apt install ffmpeg

# macOS (przez Homebrew)
brew install ffmpeg
```

### GAJA Server niedostÄ™pny
```bash
# SprawdÅº status
curl http://localhost:8001/health

# Restart Docker
cd ../Gaja-server
docker compose restart
```

### LM Studio niedostÄ™pny
- Uruchom LM Studio
- ZaÅ‚aduj model gpt-oss-20b (lub inny zgodny)
- SprawdÅº czy server endpoint jest aktywny na porcie 1234
- Ocena semantyczna bÄ™dzie pominiÄ™ta jeÅ›li LM Studio niedostÄ™pny

### BÅ‚Ä™dy TTS
- SprawdÅº klucz `OPENAI_API_KEY` w `.env`
- SprawdÅº limit API OpenAI
- SprawdÅº poÅ‚Ä…czenie internetowe

### BÅ‚Ä™dy autoryzacji GAJA
- SprawdÅº czy `GAJA_API_KEY` jest ustawiony (jeÅ›li wymagany)
- SprawdÅº endpoint autoryzacji w `api/routes.py`

## ğŸ” PrzykÅ‚ad uruchomienia

```bash
# Terminal 1: Uruchom serwisy
cd ../Gaja-server && docker compose up -d
cd ../Gaja-Web && docker compose up -d

# Terminal 2: Uruchom LM Studio (opcjonalnie)
# Uruchom aplikacjÄ™ LM Studio i zaÅ‚aduj model

# Terminal 3: Uruchom testy
cd Gaja-full-test
python src/runner.py --all
```

Oczekiwany wynik:
```
2025-08-09 13:30:00 | INFO | âœ… Configuration loaded and validated
2025-08-09 13:30:01 | INFO | âœ… FFmpeg available
2025-08-09 13:30:01 | INFO | âœ… All components initialized
2025-08-09 13:30:02 | INFO | âœ… GAJA Server is healthy
2025-08-09 13:30:03 | INFO | âœ… LM Studio is available
2025-08-09 13:30:04 | INFO | âœ… Authenticated successfully
2025-08-09 13:30:05 | INFO | âœ… Loaded scenario: Basic Conversation
...
2025-08-09 13:35:30 | INFO | ğŸ“– Report generated and opened: results/report.html
2025-08-09 13:35:30 | INFO | ğŸ‰ Testing completed: 8/9 scenarios passed
```

## ğŸ“š Dokumentacja API

System wykorzystuje nastÄ™pujÄ…ce endpointy GAJA:

- `GET /health` - sprawdzenie stanu serwera
- `POST /api/v1/auth/login` - uwierzytelnienie
- `POST /api/v1/ai/query` - gÅ‚Ã³wny endpoint konwersacji
- `POST /api/v1/tts/stream` - generowanie TTS
- `GET /api/v1/memory` - pobieranie notatek/pamiÄ™ci
- `GET /api/v1/plugins` - lista dostÄ™pnych pluginÃ³w

## ğŸ¤ WkÅ‚ad w projekt

Aby dodaÄ‡ nowy scenariusz:

1. UtwÃ³rz plik YAML w `scenarios/`
2. Zdefiniuj metadane i kroki zgodnie ze schematem
3. Przetestuj pojedynczy scenariusz przed dodaniem do suite
4. Udokumentuj specjalne wymagania (pluginy, konfiguracja)

## ğŸ“„ Licencja

Zgodna z licencjÄ… gÅ‚Ã³wnego projektu GAJA.
